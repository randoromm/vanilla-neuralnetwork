{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5XGmsusYf28dAI0KxlPF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/randoromm/vanilla-neuralnetwork/blob/main/p5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks from Scratch"
      ],
      "metadata": {
        "id": "PtAmfLK0e9u_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "X, y = nnfs.spiral_data(100, 3)\n",
        "\n",
        "# Input feature sets capital x is a standard in ML - actual input data.\n",
        "X = [[1.0, 2.0, 3.0, 2.5],\n",
        "     [2.0, 5.0, -1.0, 2.0],\n",
        "     [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "\n",
        "class Layer_Dense:\n",
        "    \"\"\"\n",
        "    Generally we want to keep the weights around -0.1 to 0.1 in the beginning. During the development of the network\n",
        "    otherwise things can explode with all the multiplication. Good idea is to also normalize the inputs between -1 to 1.\n",
        "\n",
        "    Biases are usually kept at 0 by default. If you notice that the outputs are not generated, it might mean that\n",
        "    the network is dead. Then adding non-zero bias might make sense.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        # Initialising weights the other way than before.\n",
        "        # This way we avoid 1 extra transpose every time we do a forward.\n",
        "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)  # Expects shape in separate parameters\n",
        "        self.biases = np.zeros((1, n_neurons))  # Expects a shape on 1st argument, there4 tuple\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "class Activation_ReLU:\n",
        "    def forward(self, inputs):\n",
        "        self.output = np.maximum(0, inputs)\n",
        "\n",
        "\n",
        "# The number of inputs is how many features are inside each sample\n",
        "# Number of neurons can be whatever you choose.\n",
        "layer1 = Layer_Dense(4, 5)\n",
        "# On layer 2, the inputs must match the outputs of layer 1\n",
        "layer2 = Layer_Dense(5, 2)\n",
        "\n",
        "layer1.forward(X)\n",
        "print(f\"Layer1 output: \\n{layer1.output}\")\n",
        "layer2.forward(layer1.output)\n",
        "print(f\"Layer2 output: \\n{layer2.output}\")"
      ],
      "metadata": {
        "id": "6is5Vucnh8P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nnfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSY_ZUIbo0OI",
        "outputId": "87721952-22cd-462b-9c2f-998b9b641fc3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'nnfs' from '/usr/local/lib/python3.10/dist-packages/nnfs/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reserved for output area\n",
        "\n",
        "\n",
        "\n",
        "# Reserved for output area"
      ],
      "metadata": {
        "id": "2iVROX8phHLD"
      }
    }
  ]
}